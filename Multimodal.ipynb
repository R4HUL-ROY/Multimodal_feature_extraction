{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/R4HUL-ROY/Multimodal_feature_extraction/blob/main/Multimodal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-snMEQ4G0Ke"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.8\n",
        "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7Ch6N2R2G7uX"
      },
      "outputs": [],
      "source": [
        "# !pip install -q tensorflow_text\n",
        "# !pip install fasttext\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "# import fasttext.util\n",
        "\n",
        "# import tensorflow_hub as hub\n",
        "# import tensorflow_text as text\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.optimizers import Adam, Adamax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "q0i8Eg_3XTZj"
      },
      "outputs": [],
      "source": [
        "merged_dataset_path = \"/content/drive/MyDrive/project_resources/dataset/merged_data_for_multimodal_model.csv\"\n",
        "stopwords_path = \"/content/drive/MyDrive/project_resources/stopwords/stopwords.txt\"\n",
        "glove_vector_path = '/content/drive/MyDrive/project_resources/glove_model/glove.6B.200d.txt'\n",
        "fasttext_model_path = 'cc.en.300.bin'\n",
        "\n",
        "vgg16_imagenet_weight_path = \"/content/drive/MyDrive/project_resources/Imagenet_weights/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
        "resnet50_imagenet_weight_path = \"/content/drive/MyDrive/project_resources/Imagenet_weights/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
        "mobilenetv2_imagenet_weight_path = \"/content/drive/MyDrive/project_resources/Imagenet_weights/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ITSwycg8AzG"
      },
      "source": [
        "# Read the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QemE440Q711U"
      },
      "outputs": [],
      "source": [
        "# img_data_root = pathlib.Path('/content/drive/MyDrive/project_resources/dataset/Tobacco3482-jpg')\n",
        "# print(img_data_root)\n",
        "# for item in img_data_root.iterdir():\n",
        "#   print(item)\n",
        "\n",
        "# print()\n",
        "\n",
        "# text_data_root = pathlib.Path('/content/drive/MyDrive/project_resources/dataset/tobaco_OCR')\n",
        "# print(text_data_root)\n",
        "# for item in text_data_root.iterdir():\n",
        "#   print(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hcVePal713n"
      },
      "outputs": [],
      "source": [
        "# def get_corresponding_txtpath(img_path):\n",
        "#     return img_path.replace(\"Tobacco3482-jpg\", \"tobaco_OCR\")[:-3] + \"txt\"\n",
        "    \n",
        "\n",
        "# def get_file_paths_and_labels(img_data_root, text_data_root):\n",
        "#      img_paths = [str(path) for path in img_data_root.glob('*/*.jpg')]\n",
        "#      text_paths = [get_corresponding_txtpath(this_path) for this_path in img_paths]\n",
        "#      img_labels = [p.split(\"/\")[-2] for p in img_paths]\n",
        "#      text_labels = [p.split(\"/\")[-2] for p in text_paths]\n",
        "#      return img_paths, img_labels, text_paths, text_labels\n",
        "\n",
        "# img_paths, img_labels, text_paths, text_labels = get_file_paths_and_labels(img_data_root, text_data_root)\n",
        "# print(len(img_paths))\n",
        "# print(len(img_labels))\n",
        "# print(len(text_paths))\n",
        "# print(len(text_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62pTUy397157"
      },
      "outputs": [],
      "source": [
        "# def get_text_from_path(path):\n",
        "#     with open(path) as f:\n",
        "#         lines = f.readlines()\n",
        "#         lines  = ' '.join(lines)\n",
        "#         f.close()\n",
        "#     return lines\n",
        "\n",
        "# out_text = get_text_from_path('/content/drive/MyDrive/tobaco_OCR/ADVE/0000435350.txt') \n",
        "# print(out_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14f57wf1718Y"
      },
      "outputs": [],
      "source": [
        "# text_contains = []\n",
        "# c= 0 \n",
        "# for i, this_path in enumerate(text_paths):\n",
        "#     text_contains.append(get_text_from_path(this_path))\n",
        "#     print(c, end= \" \")\n",
        "#     c +=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yv6B8lgM71-_"
      },
      "outputs": [],
      "source": [
        "# df = pd.DataFrame(list(zip(text_paths, text_contains, img_paths, img_labels)),\n",
        "#                columns =['text_paths','texts', 'img_paths', 'data_label'])\n",
        "\n",
        "# # Merged Dataframe\n",
        "# df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6RWknWGtKZS"
      },
      "outputs": [],
      "source": [
        "# df.to_csv(\"merged_data_for_multimodal_model.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKebaiqDNnmG"
      },
      "source": [
        "# Read dataset from csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "EQkVjvVIG7VZ",
        "outputId": "af96b0b2-4079-47dd-edd2-dbc26a0f9028"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3482\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          text_paths  \\\n",
              "0  /content/drive/MyDrive/project_resources/datas...   \n",
              "1  /content/drive/MyDrive/project_resources/datas...   \n",
              "2  /content/drive/MyDrive/project_resources/datas...   \n",
              "3  /content/drive/MyDrive/project_resources/datas...   \n",
              "4  /content/drive/MyDrive/project_resources/datas...   \n",
              "\n",
              "                                               texts  \\\n",
              "0  \\n \\n \\n \\n A Mpertant as yar\\n sesiye teaeter...   \n",
              "1  \\n TE che fitm\\n m66400 7127\\n KOOLS are the o...   \n",
              "2  SR Onrel ules cee\\n Nee dss\\n The one tales WT...   \n",
              "3  so ARN Rr nr\\n BWR Ga ||\\n Vending Operators\\n...   \n",
              "4  \\n &\\n BR. :\\n er non\\n be 4\\n op Re eo eee ee...   \n",
              "\n",
              "                                           img_paths data_label  \n",
              "0  /content/drive/MyDrive/project_resources/datas...       ADVE  \n",
              "1  /content/drive/MyDrive/project_resources/datas...       ADVE  \n",
              "2  /content/drive/MyDrive/project_resources/datas...       ADVE  \n",
              "3  /content/drive/MyDrive/project_resources/datas...       ADVE  \n",
              "4  /content/drive/MyDrive/project_resources/datas...       ADVE  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4ede9063-b214-49f9-80ce-deb98e19eef6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_paths</th>\n",
              "      <th>texts</th>\n",
              "      <th>img_paths</th>\n",
              "      <th>data_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/project_resources/datas...</td>\n",
              "      <td>\\n \\n \\n \\n A Mpertant as yar\\n sesiye teaeter...</td>\n",
              "      <td>/content/drive/MyDrive/project_resources/datas...</td>\n",
              "      <td>ADVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/project_resources/datas...</td>\n",
              "      <td>\\n TE che fitm\\n m66400 7127\\n KOOLS are the o...</td>\n",
              "      <td>/content/drive/MyDrive/project_resources/datas...</td>\n",
              "      <td>ADVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/project_resources/datas...</td>\n",
              "      <td>SR Onrel ules cee\\n Nee dss\\n The one tales WT...</td>\n",
              "      <td>/content/drive/MyDrive/project_resources/datas...</td>\n",
              "      <td>ADVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/project_resources/datas...</td>\n",
              "      <td>so ARN Rr nr\\n BWR Ga ||\\n Vending Operators\\n...</td>\n",
              "      <td>/content/drive/MyDrive/project_resources/datas...</td>\n",
              "      <td>ADVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/project_resources/datas...</td>\n",
              "      <td>\\n &amp;\\n BR. :\\n er non\\n be 4\\n op Re eo eee ee...</td>\n",
              "      <td>/content/drive/MyDrive/project_resources/datas...</td>\n",
              "      <td>ADVE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ede9063-b214-49f9-80ce-deb98e19eef6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4ede9063-b214-49f9-80ce-deb98e19eef6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4ede9063-b214-49f9-80ce-deb98e19eef6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df = pd.read_csv(merged_dataset_path)\n",
        "print(len(df))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "CvyR128bG7Xf",
        "outputId": "ddcf594c-66e0-49cf-ed00-b4e3992e38ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          text_paths  \\\n",
              "0  /content/drive/MyDrive/project_resources/datas...   \n",
              "1  /content/drive/MyDrive/project_resources/datas...   \n",
              "2  /content/drive/MyDrive/project_resources/datas...   \n",
              "3  /content/drive/MyDrive/project_resources/datas...   \n",
              "4  /content/drive/MyDrive/project_resources/datas...   \n",
              "\n",
              "                                               texts  \\\n",
              "0  \\n \\n \\n \\n A Mpertant as yar\\n sesiye teaeter...   \n",
              "1  \\n TE che fitm\\n m66400 7127\\n KOOLS are the o...   \n",
              "2  SR Onrel ules cee\\n Nee dss\\n The one tales WT...   \n",
              "3  so ARN Rr nr\\n BWR Ga ||\\n Vending Operators\\n...   \n",
              "4  \\n &\\n BR. :\\n er non\\n be 4\\n op Re eo eee ee...   \n",
              "\n",
              "                                           img_paths  data_label  \n",
              "0  /content/drive/MyDrive/project_resources/datas...           0  \n",
              "1  /content/drive/MyDrive/project_resources/datas...           0  \n",
              "2  /content/drive/MyDrive/project_resources/datas...           0  \n",
              "3  /content/drive/MyDrive/project_resources/datas...           0  \n",
              "4  /content/drive/MyDrive/project_resources/datas...           0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-56093370-baa7-4861-948c-3ac6245655b6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_paths</th>\n",
              "      <th>texts</th>\n",
              "      <th>img_paths</th>\n",
              "      <th>data_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/project_resources/datas...</td>\n",
              "      <td>\\n \\n \\n \\n A Mpertant as yar\\n sesiye teaeter...</td>\n",
              "      <td>/content/drive/MyDrive/project_resources/datas...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/project_resources/datas...</td>\n",
              "      <td>\\n TE che fitm\\n m66400 7127\\n KOOLS are the o...</td>\n",
              "      <td>/content/drive/MyDrive/project_resources/datas...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/project_resources/datas...</td>\n",
              "      <td>SR Onrel ules cee\\n Nee dss\\n The one tales WT...</td>\n",
              "      <td>/content/drive/MyDrive/project_resources/datas...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/project_resources/datas...</td>\n",
              "      <td>so ARN Rr nr\\n BWR Ga ||\\n Vending Operators\\n...</td>\n",
              "      <td>/content/drive/MyDrive/project_resources/datas...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/project_resources/datas...</td>\n",
              "      <td>\\n &amp;\\n BR. :\\n er non\\n be 4\\n op Re eo eee ee...</td>\n",
              "      <td>/content/drive/MyDrive/project_resources/datas...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-56093370-baa7-4861-948c-3ac6245655b6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-56093370-baa7-4861-948c-3ac6245655b6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-56093370-baa7-4861-948c-3ac6245655b6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "df['data_label']= le.fit_transform(df['data_label'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wB8KrpAKG7Zi",
        "outputId": "73ba4dfd-100e-45c0-f9b8-fec878f1f86b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ADVE': 0, 'Form': 2, 'Note': 6, 'Email': 1, 'News': 5, 'Resume': 8, 'Scientific': 9, 'Memo': 4, 'Report': 7, 'Letter': 3}\n"
          ]
        }
      ],
      "source": [
        "label_dict = {}\n",
        "for idx, row in enumerate(df['text_paths']):\n",
        "    path = df.at[idx, 'text_paths']\n",
        "    lab = path.split(\"/\")[-2]\n",
        "    label_dict[str(lab)] = df.at[idx, 'data_label']\n",
        "    \n",
        "print(label_dict) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HMeFaH8EG7bt"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def preprocess(text_string):\n",
        "    preprocessed_string = re.sub(r'[^\\w\\s]','',text_string)\n",
        "    preprocessed_string = preprocessed_string.replace('\\n',' ')\n",
        "    preprocessed_string = preprocessed_string.replace('_',' ')\n",
        "    preprocessed_string = re.sub(' +', ' ', preprocessed_string)\n",
        "    return preprocessed_string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lNwB2OC8G7fm",
        "outputId": "804ca495-30c4-4cc7-b80d-3fd4e4fc1090"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'count play home'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Tokenize, Lemmatize, stopwords removal\n",
        "import spacy \n",
        "import nltk\n",
        "# nlp = spacy.load(\"en\", disable=['parser', 'tagger', 'ner'])\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "# from nltk.corpus import stopwords\n",
        "# nltk.download('stopwords')\n",
        "# stops = stopwords.words(\"english\")\n",
        "\n",
        "def get_stopwords(file_path):\n",
        "    with open(file_path, \"r\") as fp:\n",
        "        content = fp.read()\n",
        "        stops = content.split(\"\\n\")\n",
        "        stops = stops[:-1]\n",
        "        fp.close()\n",
        "        return stops\n",
        "\n",
        "stops = get_stopwords(stopwords_path)\n",
        "def normalize(comment, lowercase, remove_stopwords):\n",
        "    if lowercase:\n",
        "        comment = comment.lower()\n",
        "    comment = nlp(comment)\n",
        "    lemmatized = list()\n",
        "    for word in comment:\n",
        "        lemma = word.lemma_.strip()\n",
        "        if lemma:\n",
        "            if not remove_stopwords or (remove_stopwords and lemma not in stops):\n",
        "                lemmatized.append(lemma)\n",
        "    return \" \".join(lemmatized)\n",
        "\n",
        "normalize(\"counting playing the Home\", lowercase=True, remove_stopwords=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bHN3LSknG7hZ",
        "outputId": "79fbc43b-61b9-464f-d8dc-97937f13ffa2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          text_paths  \\\n",
              "0  /content/drive/MyDrive/project_resources/datas...   \n",
              "1  /content/drive/MyDrive/project_resources/datas...   \n",
              "2  /content/drive/MyDrive/project_resources/datas...   \n",
              "3  /content/drive/MyDrive/project_resources/datas...   \n",
              "4  /content/drive/MyDrive/project_resources/datas...   \n",
              "\n",
              "                                               texts  \\\n",
              "0  mpertant yar sesiye teaetere cabiieess baely k...   \n",
              "1  te che fitm m66400 7127 kool cigarette taste g...   \n",
              "2  sr onrel ules cee nee dss one tale wt lower ta...   \n",
              "3  arn rr nr bwr ga vend operator column worth 8 ...   \n",
              "4  br er non 4 op eo eee ee eee talk smoking deci...   \n",
              "\n",
              "                                           img_paths  data_label  \n",
              "0  /content/drive/MyDrive/project_resources/datas...           0  \n",
              "1  /content/drive/MyDrive/project_resources/datas...           0  \n",
              "2  /content/drive/MyDrive/project_resources/datas...           0  \n",
              "3  /content/drive/MyDrive/project_resources/datas...           0  \n",
              "4  /content/drive/MyDrive/project_resources/datas...           0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-15873395-9b1b-4c28-9158-b3f1e1804001\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_paths</th>\n",
              "      <th>texts</th>\n",
              "      <th>img_paths</th>\n",
              "      <th>data_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/project_resources/datas...</td>\n",
              "      <td>mpertant yar sesiye teaetere cabiieess baely k...</td>\n",
              "      <td>/content/drive/MyDrive/project_resources/datas...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/project_resources/datas...</td>\n",
              "      <td>te che fitm m66400 7127 kool cigarette taste g...</td>\n",
              "      <td>/content/drive/MyDrive/project_resources/datas...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/project_resources/datas...</td>\n",
              "      <td>sr onrel ules cee nee dss one tale wt lower ta...</td>\n",
              "      <td>/content/drive/MyDrive/project_resources/datas...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/project_resources/datas...</td>\n",
              "      <td>arn rr nr bwr ga vend operator column worth 8 ...</td>\n",
              "      <td>/content/drive/MyDrive/project_resources/datas...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/project_resources/datas...</td>\n",
              "      <td>br er non 4 op eo eee ee eee talk smoking deci...</td>\n",
              "      <td>/content/drive/MyDrive/project_resources/datas...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-15873395-9b1b-4c28-9158-b3f1e1804001')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-15873395-9b1b-4c28-9158-b3f1e1804001 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-15873395-9b1b-4c28-9158-b3f1e1804001');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df['texts'] = [preprocess(str(this_text)) for this_text in df['texts']]\n",
        "df['texts'] = [normalize(this_text, lowercase=True, remove_stopwords=True) for this_text in df['texts']]\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0xyXKSByG7k7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6VoNrI5cG7m0"
      },
      "outputs": [],
      "source": [
        "def dataframe_to_dataset(dataframe):\n",
        "    d = {}\n",
        "    embed_tensor = []\n",
        "    for i in dataframe['texts_embedding']:\n",
        "        embed_tensor.append(tf.convert_to_tensor(i))\n",
        "\n",
        "    img_path_tensor= []\n",
        "    for i in dataframe['img_paths']:\n",
        "        img_path_tensor.append(tf.convert_to_tensor(i))\n",
        "\n",
        "    d['texts_embedding'] = embed_tensor\n",
        "    d['img_paths'] = img_path_tensor\n",
        "\n",
        "    labels = dataframe[\"data_label\"]\n",
        "    labels = tf.convert_to_tensor(labels)\n",
        "    ds = tf.data.Dataset.from_tensor_slices((d, labels))\n",
        "    return ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FPkfitFvG7o0"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def preprocess_image(image_path):\n",
        "    extension = tf.strings.split(image_path)[-1]\n",
        "\n",
        "    image = tf.io.read_file(image_path)\n",
        "    if extension == b\"jpg\":\n",
        "        image = tf.image.decode_jpeg(image, 3)\n",
        "    else:\n",
        "        image = tf.image.decode_png(image, 3)\n",
        "    image = tf.image.resize(image, (224, 224))\n",
        "    image = tf.image.per_image_standardization(image)\n",
        "    return image\n",
        "\n",
        "@tf.function\n",
        "def preprocess_text(sample):\n",
        "    pass\n",
        "\n",
        "@tf.function\n",
        "def preprocess_text_and_image(sample):\n",
        "    image = preprocess_image(sample[\"img_paths\"])\n",
        "    text = sample['texts_embedding']\n",
        "    return {\"image_inputs\": image,  \"text_inputs\": text}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "J88nwUvfG7qp"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "auto = tf.data.AUTOTUNE\n",
        "\n",
        "def prepare_dataset(dataframe, training = True):\n",
        "    ds = dataframe_to_dataset(dataframe)\n",
        "    if training:\n",
        "        ds = ds.shuffle(len(train_df))\n",
        "    ds = ds.map(lambda x, y: (preprocess_text_and_image(x), y)).cache()\n",
        "    ds = ds.batch(batch_size).prefetch(auto)\n",
        "    return ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "aZHvW1L2HmtB"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Flatten,  Dense, Dropout, Conv1D, GlobalMaxPooling1D, MaxPooling1D, GlobalMaxPooling2D\n",
        "from keras.initializers import Constant\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "pljgtsK9In4l"
      },
      "outputs": [],
      "source": [
        "def get_embedding_matrix(text_model):\n",
        "    if text_model == \"glove\":\n",
        "        emmbed_dict = {}\n",
        "        with open(glove_vector_path ,'r') as f:\n",
        "            for line in f:\n",
        "                values = line.split()\n",
        "                word = values[0]\n",
        "                vector = np.asarray(values[1:],'float32')\n",
        "                emmbed_dict[word]=vector\n",
        "            f.close()\n",
        "        embedding_matrix = np.zeros((num_words, 200))\n",
        "        for word, i in word_index.items():\n",
        "            if i < num_words:\n",
        "                emb_vec = emmbed_dict.get(word)\n",
        "                if emb_vec is not None:\n",
        "                    embedding_matrix[i] = emb_vec\n",
        "        return embedding_matrix \n",
        "\n",
        "    elif text_model == \"fasttext\":  \n",
        "        ft = fasttext.load_model(fasttext_model_path)    \n",
        "        embedding_matrix = np.zeros((num_words, 300)) \n",
        "        for word, i in word_index.items():\n",
        "            if i < num_words:\n",
        "                emb_vec = ft.get_word_vector(word)\n",
        "                if emb_vec is not None:\n",
        "                    embedding_matrix[i] = emb_vec \n",
        "        return embedding_matrix    \n",
        "    else:    \n",
        "        return None                                       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ohTkuTPRHmvI"
      },
      "outputs": [],
      "source": [
        "def create_text_encoder(text_projection_dims, dropout_rate, text_model, text_model_trainable):\n",
        "\n",
        "    embedding_matrix = get_embedding_matrix(text_model)\n",
        "\n",
        "    filter_size = 128\n",
        "    stride_unit = 1\n",
        "    kernels = 3\n",
        "    dropout_rate = 0.2\n",
        "    dropout_rate_conv = 0.5\n",
        "\n",
        "    inputs = keras.Input(shape=(500,), dtype=tf.int32, name=\"text_inputs\")\n",
        "\n",
        "    if text_model == \"glove\":\n",
        "        embed = tf.keras.layers.Embedding(  num_words,\n",
        "                                            200,\n",
        "                                            input_length = 500,\n",
        "                                            embeddings_initializer = Constant(embedding_matrix),\n",
        "                                            trainable = text_model_trainable\n",
        "                                        )(inputs)\n",
        "    if text_model == \"fasttext\":\n",
        "        embed = tf.keras.layers.Embedding(  num_words,\n",
        "                                            300,\n",
        "                                            input_length = 500,\n",
        "                                            embeddings_initializer = Constant(embedding_matrix),\n",
        "                                            trainable = text_model_trainable\n",
        "                                        )(inputs)\n",
        "\n",
        "    x = tf.keras.layers.Dropout(dropout_rate)(embed)\n",
        "\n",
        "\n",
        "    x = tf.keras.layers.Conv1D(filters=filter_size,kernel_size=kernels, padding='valid',activation='relu',strides=stride_unit,\n",
        "                               kernel_initializer = \"glorot_uniform\" ,bias_initializer = 'zeros')(x)\n",
        "    x = tf.keras.layers.MaxPooling1D()(x)\n",
        "    x = tf.keras.layers.Dropout(dropout_rate_conv)(x)\n",
        "\n",
        "    x = tf.keras.layers.Conv1D(filters=filter_size,kernel_size=kernels, padding='valid',activation='relu',strides=stride_unit,\n",
        "                               kernel_initializer = \"glorot_uniform\" ,bias_initializer = 'zeros')(x)\n",
        "    x = tf.keras.layers.MaxPooling1D()(x)\n",
        "    x = tf.keras.layers.Dropout(dropout_rate_conv)(x)\n",
        "\n",
        "    x = tf.keras.layers.Conv1D(filters=filter_size,kernel_size=kernels, padding='valid',activation='relu',strides=stride_unit,\n",
        "                               kernel_initializer = \"glorot_uniform\" ,bias_initializer = 'zeros')(x)\n",
        "    x = tf.keras.layers.MaxPooling1D()(x)\n",
        "    x = tf.keras.layers.Dropout(dropout_rate_conv)(x)\n",
        "    \n",
        "    x = tf.keras.layers.Conv1D(filters=filter_size,kernel_size=kernels, padding='valid',activation='relu',strides=stride_unit,\n",
        "                               kernel_initializer = \"glorot_uniform\" ,bias_initializer = 'zeros')(x)\n",
        "    x = tf.keras.layers.MaxPooling1D()(x)\n",
        "    x = tf.keras.layers.Dropout(dropout_rate_conv)(x)\n",
        "\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "    # x = tf.math.l2_normalize(x)\n",
        "    x = tf.keras.layers.Dropout(dropout_rate_conv)(x)\n",
        "     \n",
        "    outputs = keras.layers.Dense(units=text_projection_dims,activation=\"relu\",kernel_initializer=\"glorot_uniform\",bias_initializer='zeros')(x)\n",
        "    return keras.Model(inputs, outputs, name=\"text_encoder\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "YUavauzSHmxE"
      },
      "outputs": [],
      "source": [
        "def create_vision_encoder(img_projection_dims, dropout_rate, image_model, img_base_model_trainable):\n",
        "    img_shape=(224,224,3)\n",
        "    seed_value = 42\n",
        "\n",
        "\n",
        "    if image_model == \"vgg16\":\n",
        "        base_model = tf.keras.applications.vgg16.VGG16(include_top=False,input_shape=img_shape,pooling='avg',classes=10,weights=None)\n",
        "        base_model.load_weights(vgg16_imagenet_weight_path)\n",
        "        base_model.trainable = img_base_model_trainable\n",
        "\n",
        "    elif image_model == \"resnet50\":\n",
        "        base_model= tf.keras.applications.ResNet50(include_top=False,input_shape=img_shape,pooling='avg',classes=10,weights=None)\n",
        "        base_model.load_weights(resnet50_imagenet_weight_path)\n",
        "        base_model.trainable = img_base_model_trainable\n",
        "\n",
        "    elif image_model == \"mobilenetv2\":\n",
        "        base_model=tf.keras.applications.MobileNetV2(include_top=False,input_shape=img_shape,pooling='avg', classes=10,weights=None)\n",
        "        base_model.load_weights(mobilenetv2_imagenet_weight_path)\n",
        "        base_model.trainable = img_base_model_trainable\n",
        "\n",
        "\n",
        "    inputs = keras.Input(shape=img_shape)\n",
        "    x = base_model(inputs, training = img_base_model_trainable)\n",
        "    outputs =tf.keras.layers.Dense(img_projection_dims,kernel_initializer =\"glorot_uniform\",bias_initializer= \"zeros\",activation='relu')(x)\n",
        "\n",
        "    model=Model(inputs, outputs)\n",
        "\n",
        "    # Receive the images as inputs.\n",
        "    image_inputs = keras.Input(shape=(224, 224, 3), name=\"image_inputs\")\n",
        "\n",
        "    if image_model == \"vgg16\":\n",
        "        preprocessed_image = tf.keras.applications.vgg16.preprocess_input(image_inputs)\n",
        "    if image_model == \"resnet50\":\n",
        "        preprocessed_image = tf.keras.applications.resnet50.preprocess_input(image_inputs)    \n",
        "    if image_model == \"mobilenetv2\":\n",
        "        preprocessed_image = tf.keras.applications.mobilenet_v2.preprocess_input(image_inputs)\n",
        "\n",
        "    embeddings = model(preprocessed_image)\n",
        "\n",
        "    # Create the vision encoder model.\n",
        "    return keras.Model(image_inputs, embeddings, name=\"vision_encoder\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "bSJ8B8tqHmzA"
      },
      "outputs": [],
      "source": [
        "def create_multimodal_model(**kwargs):\n",
        "\n",
        "    img_projection_dims = kwargs['img_projection_dims']\n",
        "    text_projection_dims = kwargs['text_projection_dims']\n",
        "    dropout_rate = kwargs['dropout_rate']\n",
        "    image_model = kwargs['image_model']\n",
        "    text_model = kwargs['text_model']\n",
        "    img_base_model_trainable = kwargs['img_base_model_trainable']\n",
        "    text_model_trainable = kwargs['text_model_trainable']\n",
        "\n",
        "    if image_model == \"None\" and text_model == \"None\":\n",
        "        print(\"Both the image_model and text_model cannot be None at the same time !!\")\n",
        "        return\n",
        "    # Receive the images and text as inputs.\n",
        "    if image_model != \"None\":\n",
        "        image_inputs = keras.Input(shape=(224, 224, 3), name=\"image_inputs\")\n",
        "        vision_encoder = create_vision_encoder(img_projection_dims, dropout_rate, image_model, img_base_model_trainable)\n",
        "        vision_projections = vision_encoder(image_inputs)\n",
        "\n",
        "    if text_model != \"None\":   \n",
        "        text_inputs = keras.Input(shape=(500,), dtype=tf.int32, name=\"text_inputs\")\n",
        "        text_encoder = create_text_encoder(text_projection_dims, dropout_rate, text_model, text_model_trainable)\n",
        "        text_projections = text_encoder(text_inputs)\n",
        "\n",
        "\n",
        "    # Concatenate the projections and pass through the classification layer.\n",
        "    if image_model != \"None\" and text_model != \"None\":\n",
        "        concatenated = keras.layers.Concatenate()([vision_projections, text_projections])\n",
        "    # concatenated = tf.keras.layers.BatchNormalization(momentum=0.9)(concatenated)\n",
        "\n",
        "\n",
        "    if image_model == \"None\" and text_model != \"None\":\n",
        "        outputs = keras.layers.Dense(10, activation=\"softmax\")(text_projections)\n",
        "        return keras.Model(text_inputs, outputs)\n",
        "    elif text_model == \"None\" and image_model != \"None\":    \n",
        "        outputs = keras.layers.Dense(10, activation=\"softmax\")(vision_projections)\n",
        "        return keras.Model(image_inputs, outputs)\n",
        "    elif text_model != \"None\" and image_model != \"None\":\n",
        "        outputs = keras.layers.Dense(10, activation=\"softmax\")(concatenated)\n",
        "        return keras.Model([image_inputs, text_inputs], outputs)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HTg_FrCR2Tmh"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import random\n",
        "random.seed(56)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "zGOrDCFc1j1e",
        "outputId": "c1f06ca4-df57-4a17-f83b-92b7e724362f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Run:  1\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:559: UserWarning: Input dict contained keys ['text_inputs'] which did not match any model input. They will be ignored by the model.\n",
            "  inputs = self._flatten_to_reference_inputs(inputs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44/44 - 1707s - loss: 1.7982 - accuracy: 0.4036 - val_loss: 1.5649 - val_accuracy: 0.4413 - 1707s/epoch - 39s/step\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-4a9af89a5a21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mmultimodal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdamax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sparse_categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultimodal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "epochs = 50\n",
        "fine_tune_epochs = 5\n",
        "lr = 0.001\n",
        "\n",
        "d = {\n",
        "    \"precision\" : [],\n",
        "     \"recall\" : [],\n",
        "     \"f1_score\" : [],\n",
        "     \"accuracy\" : [],\n",
        "     \"seed_value\" : []\n",
        "}\n",
        "seed = []\n",
        "\n",
        "for i in range(1):\n",
        "    print('#Run: ', i+1)\n",
        "    sd = random.randint(0, 100)\n",
        "    seed.append(sd)\n",
        "\n",
        "    # Split the dataframe\n",
        "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=sd)\n",
        "    test_df, val_df = train_test_split(test_df, test_size=0.5, random_state=sd)\n",
        "\n",
        "    max_len = 500\n",
        "    # Fit the tokenizer\n",
        "    tokenizer = Tokenizer(num_words=65000)\n",
        "    tokenizer.fit_on_texts(train_df['texts'])\n",
        "\n",
        "    # sequence the input corpus and add zero padding upto 500 word\n",
        "    train_sequence = tokenizer.texts_to_sequences(train_df['texts'])\n",
        "    train_padded = pad_sequences(train_sequence, maxlen = max_len, truncating = \"post\", padding = \"post\" )\n",
        "\n",
        "    valid_sequence = tokenizer.texts_to_sequences(val_df['texts'])\n",
        "    valid_padded = pad_sequences(valid_sequence, maxlen = max_len, truncating = \"post\", padding = \"post\" )\n",
        "\n",
        "    test_sequence = tokenizer.texts_to_sequences(test_df['texts'])\n",
        "    test_padded = pad_sequences(test_sequence, maxlen = max_len, truncating = \"post\", padding = \"post\" )\n",
        "\n",
        "    train_tensor = [tf.convert_to_tensor(train_padded[i]) for i in range(train_padded.shape[0])]\n",
        "    train_df['texts_embedding'] = train_tensor\n",
        "\n",
        "    test_tensor = [tf.convert_to_tensor(test_padded[i]) for i in range(test_padded.shape[0])]\n",
        "    test_df['texts_embedding'] = test_tensor   \n",
        "\n",
        "    val_tensor = [tf.convert_to_tensor(valid_padded[i]) for i in range(valid_padded.shape[0])]\n",
        "    val_df['texts_embedding'] = val_tensor\n",
        "\n",
        "    # Preparing dataset\n",
        "    train_ds = prepare_dataset(train_df)\n",
        "    val_ds = prepare_dataset(val_df, False)\n",
        "    test_ds = prepare_dataset(test_df, False)\n",
        "\n",
        "    word_index = tokenizer.word_index\n",
        "    num_words = len(word_index) + 1\n",
        "\n",
        "    \"\"\"\n",
        "    options for image_model : [\"vgg16\", \"resnet50\", \"mobilenetv2\"] (case-sensitive input)\n",
        "    options for text_model : [\"glove\", \"fasttext\"] (case-sensitive input)\n",
        "    \"\"\"\n",
        "\n",
        "    multimodal_model = create_multimodal_model( \n",
        "        img_projection_dims=512,\n",
        "        text_projection_dims=512,\n",
        "        dropout_rate=0.2,\n",
        "        image_model = \"None\",\n",
        "        text_model = \"glove\", \n",
        "        img_base_model_trainable=False,\n",
        "        text_model_trainable= False\n",
        "    )\n",
        "\n",
        "    multimodal_model.compile(Adamax(learning_rate=0.001), loss=\"sparse_categorical_crossentropy\", metrics=\"accuracy\")\n",
        "    history = multimodal_model.fit(train_ds, validation_data=val_ds, epochs=10, verbose=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKZZf2FtIV2z"
      },
      "outputs": [],
      "source": [
        "keras.utils.plot_model(multimodal_model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "Mm8hUuz_I5iJ",
        "outputId": "522c4c81-c533-4a69-a9b8-3ebc7168f8a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:559: UserWarning: Input dict contained keys ['image_inputs'] which did not match any model input. They will be ignored by the model.\n",
            "  inputs = self._flatten_to_reference_inputs(inputs)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-c50af7b7d8bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultimodal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "history = multimodal_model.fit(train_ds, validation_data=val_ds, epochs=50, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePzhQCJ3I23z"
      },
      "outputs": [],
      "source": [
        "model.save('/content')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNILrVExHm26"
      },
      "outputs": [],
      "source": [
        "# multimodal_model.compile(Adamax(learning_rate=0.001), loss=\"sparse_categorical_crossentropy\", metrics=\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5F4mQHJjHm46"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EkMs6TyHm8j",
        "outputId": "0d18516e-42b1-453d-d010-298ed209f8e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<keras.engine.input_layer.InputLayer at 0x7fcc93add990>,\n",
              " <keras.engine.input_layer.InputLayer at 0x7fcc92238890>,\n",
              " <keras.engine.functional.Functional at 0x7fcc922382d0>,\n",
              " <keras.engine.functional.Functional at 0x7fcf00e72790>,\n",
              " <keras.layers.merge.Concatenate at 0x7fcf300eca90>,\n",
              " <keras.layers.core.dense.Dense at 0x7fcf0a189790>]"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# multimodal_model.layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlqvssvEHm-Q",
        "outputId": "1ab49d00-f169-4846-8ad4-3e2e4f32ccfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "44/44 - 1s - loss: 0.6351 - accuracy: 0.7767 - val_loss: 0.7052 - val_accuracy: 0.7564 - 989ms/epoch - 22ms/step\n",
            "Epoch 2/70\n",
            "44/44 - 1s - loss: 0.6031 - accuracy: 0.7741 - val_loss: 0.7010 - val_accuracy: 0.7450 - 996ms/epoch - 23ms/step\n",
            "Epoch 3/70\n",
            "44/44 - 1s - loss: 0.6015 - accuracy: 0.7835 - val_loss: 0.7074 - val_accuracy: 0.7393 - 935ms/epoch - 21ms/step\n",
            "Epoch 4/70\n",
            "44/44 - 1s - loss: 0.6125 - accuracy: 0.7871 - val_loss: 0.7120 - val_accuracy: 0.7421 - 1s/epoch - 24ms/step\n",
            "Epoch 5/70\n",
            "44/44 - 1s - loss: 0.5775 - accuracy: 0.7903 - val_loss: 0.6916 - val_accuracy: 0.7421 - 982ms/epoch - 22ms/step\n",
            "Epoch 6/70\n",
            "44/44 - 1s - loss: 0.5801 - accuracy: 0.7896 - val_loss: 0.6914 - val_accuracy: 0.7479 - 948ms/epoch - 22ms/step\n",
            "Epoch 7/70\n",
            "44/44 - 1s - loss: 0.5661 - accuracy: 0.7925 - val_loss: 0.7010 - val_accuracy: 0.7479 - 984ms/epoch - 22ms/step\n",
            "Epoch 8/70\n",
            "44/44 - 1s - loss: 0.5634 - accuracy: 0.8043 - val_loss: 0.6943 - val_accuracy: 0.7536 - 972ms/epoch - 22ms/step\n",
            "Epoch 9/70\n",
            "44/44 - 1s - loss: 0.5415 - accuracy: 0.8101 - val_loss: 0.6724 - val_accuracy: 0.7536 - 889ms/epoch - 20ms/step\n",
            "Epoch 10/70\n",
            "44/44 - 1s - loss: 0.5361 - accuracy: 0.8093 - val_loss: 0.6871 - val_accuracy: 0.7479 - 976ms/epoch - 22ms/step\n",
            "Epoch 11/70\n",
            "44/44 - 1s - loss: 0.5412 - accuracy: 0.8079 - val_loss: 0.7103 - val_accuracy: 0.7564 - 1s/epoch - 23ms/step\n",
            "Epoch 12/70\n",
            "44/44 - 1s - loss: 0.5293 - accuracy: 0.8126 - val_loss: 0.6672 - val_accuracy: 0.7536 - 1s/epoch - 32ms/step\n",
            "Epoch 13/70\n",
            "44/44 - 1s - loss: 0.5242 - accuracy: 0.8129 - val_loss: 0.6816 - val_accuracy: 0.7650 - 929ms/epoch - 21ms/step\n",
            "Epoch 14/70\n",
            "44/44 - 1s - loss: 0.5157 - accuracy: 0.8079 - val_loss: 0.6758 - val_accuracy: 0.7593 - 726ms/epoch - 16ms/step\n",
            "Epoch 15/70\n",
            "44/44 - 1s - loss: 0.5000 - accuracy: 0.8244 - val_loss: 0.6682 - val_accuracy: 0.7650 - 773ms/epoch - 18ms/step\n",
            "Epoch 16/70\n",
            "44/44 - 1s - loss: 0.5085 - accuracy: 0.8180 - val_loss: 0.6831 - val_accuracy: 0.7507 - 744ms/epoch - 17ms/step\n",
            "Epoch 17/70\n",
            "44/44 - 1s - loss: 0.4958 - accuracy: 0.8266 - val_loss: 0.6681 - val_accuracy: 0.7679 - 723ms/epoch - 16ms/step\n",
            "Epoch 18/70\n",
            "44/44 - 1s - loss: 0.4918 - accuracy: 0.8219 - val_loss: 0.6872 - val_accuracy: 0.7536 - 732ms/epoch - 17ms/step\n",
            "Epoch 19/70\n",
            "44/44 - 1s - loss: 0.5023 - accuracy: 0.8162 - val_loss: 0.6815 - val_accuracy: 0.7564 - 755ms/epoch - 17ms/step\n",
            "Epoch 20/70\n",
            "44/44 - 1s - loss: 0.4969 - accuracy: 0.8215 - val_loss: 0.6685 - val_accuracy: 0.7736 - 765ms/epoch - 17ms/step\n",
            "Epoch 21/70\n",
            "44/44 - 1s - loss: 0.4779 - accuracy: 0.8269 - val_loss: 0.6561 - val_accuracy: 0.7822 - 752ms/epoch - 17ms/step\n",
            "Epoch 22/70\n",
            "44/44 - 1s - loss: 0.4851 - accuracy: 0.8259 - val_loss: 0.6640 - val_accuracy: 0.7708 - 727ms/epoch - 17ms/step\n",
            "Epoch 23/70\n",
            "44/44 - 1s - loss: 0.4619 - accuracy: 0.8294 - val_loss: 0.6627 - val_accuracy: 0.7765 - 751ms/epoch - 17ms/step\n",
            "Epoch 24/70\n",
            "44/44 - 1s - loss: 0.4482 - accuracy: 0.8399 - val_loss: 0.6666 - val_accuracy: 0.7650 - 744ms/epoch - 17ms/step\n",
            "Epoch 25/70\n",
            "44/44 - 1s - loss: 0.4398 - accuracy: 0.8402 - val_loss: 0.6725 - val_accuracy: 0.7679 - 750ms/epoch - 17ms/step\n",
            "Epoch 26/70\n",
            "44/44 - 1s - loss: 0.4391 - accuracy: 0.8481 - val_loss: 0.6750 - val_accuracy: 0.7708 - 741ms/epoch - 17ms/step\n",
            "Epoch 27/70\n",
            "44/44 - 1s - loss: 0.4278 - accuracy: 0.8445 - val_loss: 0.6581 - val_accuracy: 0.7794 - 766ms/epoch - 17ms/step\n",
            "Epoch 28/70\n",
            "44/44 - 1s - loss: 0.4286 - accuracy: 0.8499 - val_loss: 0.6668 - val_accuracy: 0.7679 - 752ms/epoch - 17ms/step\n",
            "Epoch 29/70\n",
            "44/44 - 1s - loss: 0.4300 - accuracy: 0.8521 - val_loss: 0.6668 - val_accuracy: 0.7622 - 739ms/epoch - 17ms/step\n",
            "Epoch 30/70\n",
            "44/44 - 1s - loss: 0.4204 - accuracy: 0.8517 - val_loss: 0.6631 - val_accuracy: 0.7650 - 726ms/epoch - 16ms/step\n",
            "Epoch 31/70\n",
            "44/44 - 1s - loss: 0.3995 - accuracy: 0.8549 - val_loss: 0.6480 - val_accuracy: 0.7708 - 764ms/epoch - 17ms/step\n",
            "Epoch 32/70\n",
            "44/44 - 1s - loss: 0.4144 - accuracy: 0.8535 - val_loss: 0.6504 - val_accuracy: 0.7794 - 741ms/epoch - 17ms/step\n",
            "Epoch 33/70\n",
            "44/44 - 1s - loss: 0.4097 - accuracy: 0.8481 - val_loss: 0.6648 - val_accuracy: 0.7650 - 754ms/epoch - 17ms/step\n",
            "Epoch 34/70\n",
            "44/44 - 1s - loss: 0.4159 - accuracy: 0.8600 - val_loss: 0.6525 - val_accuracy: 0.7736 - 760ms/epoch - 17ms/step\n",
            "Epoch 35/70\n",
            "44/44 - 1s - loss: 0.3854 - accuracy: 0.8600 - val_loss: 0.6882 - val_accuracy: 0.7679 - 737ms/epoch - 17ms/step\n",
            "Epoch 36/70\n",
            "44/44 - 1s - loss: 0.3784 - accuracy: 0.8607 - val_loss: 0.6725 - val_accuracy: 0.7650 - 749ms/epoch - 17ms/step\n",
            "Epoch 37/70\n",
            "44/44 - 1s - loss: 0.3801 - accuracy: 0.8618 - val_loss: 0.6611 - val_accuracy: 0.7622 - 728ms/epoch - 17ms/step\n",
            "Epoch 38/70\n",
            "44/44 - 1s - loss: 0.3723 - accuracy: 0.8600 - val_loss: 0.6713 - val_accuracy: 0.7679 - 741ms/epoch - 17ms/step\n",
            "Epoch 39/70\n",
            "44/44 - 1s - loss: 0.3899 - accuracy: 0.8628 - val_loss: 0.6828 - val_accuracy: 0.7564 - 769ms/epoch - 17ms/step\n",
            "Epoch 40/70\n",
            "44/44 - 1s - loss: 0.3623 - accuracy: 0.8664 - val_loss: 0.6639 - val_accuracy: 0.7650 - 726ms/epoch - 16ms/step\n",
            "Epoch 41/70\n",
            "44/44 - 1s - loss: 0.3735 - accuracy: 0.8697 - val_loss: 0.6488 - val_accuracy: 0.7708 - 728ms/epoch - 17ms/step\n",
            "Epoch 42/70\n",
            "44/44 - 1s - loss: 0.3650 - accuracy: 0.8675 - val_loss: 0.6595 - val_accuracy: 0.7593 - 724ms/epoch - 16ms/step\n",
            "Epoch 43/70\n",
            "44/44 - 1s - loss: 0.3556 - accuracy: 0.8754 - val_loss: 0.6758 - val_accuracy: 0.7622 - 726ms/epoch - 16ms/step\n",
            "Epoch 44/70\n",
            "44/44 - 1s - loss: 0.3606 - accuracy: 0.8736 - val_loss: 0.6621 - val_accuracy: 0.7708 - 749ms/epoch - 17ms/step\n",
            "Epoch 45/70\n",
            "44/44 - 1s - loss: 0.3482 - accuracy: 0.8758 - val_loss: 0.6615 - val_accuracy: 0.7708 - 743ms/epoch - 17ms/step\n",
            "Epoch 46/70\n",
            "44/44 - 1s - loss: 0.3489 - accuracy: 0.8707 - val_loss: 0.6802 - val_accuracy: 0.7622 - 733ms/epoch - 17ms/step\n",
            "Epoch 47/70\n",
            "44/44 - 1s - loss: 0.3330 - accuracy: 0.8822 - val_loss: 0.6785 - val_accuracy: 0.7679 - 727ms/epoch - 17ms/step\n",
            "Epoch 48/70\n",
            "44/44 - 1s - loss: 0.3386 - accuracy: 0.8822 - val_loss: 0.6728 - val_accuracy: 0.7679 - 728ms/epoch - 17ms/step\n",
            "Epoch 49/70\n",
            "44/44 - 1s - loss: 0.3428 - accuracy: 0.8786 - val_loss: 0.6989 - val_accuracy: 0.7708 - 764ms/epoch - 17ms/step\n",
            "Epoch 50/70\n",
            "44/44 - 1s - loss: 0.3318 - accuracy: 0.8811 - val_loss: 0.6773 - val_accuracy: 0.7679 - 727ms/epoch - 17ms/step\n",
            "Epoch 51/70\n",
            "44/44 - 1s - loss: 0.3236 - accuracy: 0.8855 - val_loss: 0.6626 - val_accuracy: 0.7736 - 742ms/epoch - 17ms/step\n",
            "Epoch 52/70\n",
            "44/44 - 1s - loss: 0.3250 - accuracy: 0.8811 - val_loss: 0.6596 - val_accuracy: 0.7880 - 761ms/epoch - 17ms/step\n",
            "Epoch 53/70\n",
            "44/44 - 1s - loss: 0.3179 - accuracy: 0.8908 - val_loss: 0.6675 - val_accuracy: 0.7593 - 754ms/epoch - 17ms/step\n",
            "Epoch 54/70\n",
            "44/44 - 1s - loss: 0.3252 - accuracy: 0.8898 - val_loss: 0.6752 - val_accuracy: 0.7736 - 732ms/epoch - 17ms/step\n",
            "Epoch 55/70\n",
            "44/44 - 1s - loss: 0.3364 - accuracy: 0.8815 - val_loss: 0.6890 - val_accuracy: 0.7622 - 734ms/epoch - 17ms/step\n",
            "Epoch 56/70\n",
            "44/44 - 1s - loss: 0.3108 - accuracy: 0.8840 - val_loss: 0.6654 - val_accuracy: 0.7794 - 740ms/epoch - 17ms/step\n",
            "Epoch 57/70\n",
            "44/44 - 1s - loss: 0.3067 - accuracy: 0.8901 - val_loss: 0.6812 - val_accuracy: 0.7736 - 735ms/epoch - 17ms/step\n",
            "Epoch 58/70\n",
            "44/44 - 1s - loss: 0.3249 - accuracy: 0.8876 - val_loss: 0.6874 - val_accuracy: 0.7851 - 719ms/epoch - 16ms/step\n",
            "Epoch 59/70\n",
            "44/44 - 1s - loss: 0.2923 - accuracy: 0.8966 - val_loss: 0.6772 - val_accuracy: 0.7736 - 768ms/epoch - 17ms/step\n",
            "Epoch 60/70\n",
            "44/44 - 1s - loss: 0.3036 - accuracy: 0.8876 - val_loss: 0.7033 - val_accuracy: 0.7650 - 743ms/epoch - 17ms/step\n",
            "Epoch 61/70\n",
            "44/44 - 1s - loss: 0.3144 - accuracy: 0.8880 - val_loss: 0.6785 - val_accuracy: 0.7851 - 750ms/epoch - 17ms/step\n",
            "Epoch 62/70\n",
            "44/44 - 1s - loss: 0.2921 - accuracy: 0.8969 - val_loss: 0.6984 - val_accuracy: 0.7736 - 727ms/epoch - 17ms/step\n",
            "Epoch 63/70\n",
            "44/44 - 1s - loss: 0.3000 - accuracy: 0.8887 - val_loss: 0.6787 - val_accuracy: 0.7736 - 754ms/epoch - 17ms/step\n",
            "Epoch 64/70\n",
            "44/44 - 1s - loss: 0.2884 - accuracy: 0.8987 - val_loss: 0.7289 - val_accuracy: 0.7536 - 734ms/epoch - 17ms/step\n",
            "Epoch 65/70\n",
            "44/44 - 1s - loss: 0.3019 - accuracy: 0.8930 - val_loss: 0.6839 - val_accuracy: 0.7736 - 746ms/epoch - 17ms/step\n",
            "Epoch 66/70\n",
            "44/44 - 1s - loss: 0.2911 - accuracy: 0.9074 - val_loss: 0.6913 - val_accuracy: 0.7794 - 730ms/epoch - 17ms/step\n",
            "Epoch 67/70\n",
            "44/44 - 1s - loss: 0.2755 - accuracy: 0.9002 - val_loss: 0.6997 - val_accuracy: 0.7536 - 701ms/epoch - 16ms/step\n",
            "Epoch 68/70\n",
            "44/44 - 1s - loss: 0.2735 - accuracy: 0.9041 - val_loss: 0.7009 - val_accuracy: 0.7736 - 727ms/epoch - 17ms/step\n",
            "Epoch 69/70\n",
            "44/44 - 1s - loss: 0.2885 - accuracy: 0.8980 - val_loss: 0.7029 - val_accuracy: 0.7622 - 765ms/epoch - 17ms/step\n",
            "Epoch 70/70\n",
            "44/44 - 1s - loss: 0.2714 - accuracy: 0.8966 - val_loss: 0.6874 - val_accuracy: 0.7736 - 769ms/epoch - 17ms/step\n"
          ]
        }
      ],
      "source": [
        "# history_fine = multimodal_model.fit(train_ds, validation_data=val_ds, epochs=60, verbose=2)\n",
        "# \n",
        "# y_pred = multimodal_model.predict(test_ds)\n",
        "# y_pred = [np.argmax(i) for i in y_pred]\n",
        "\n",
        "# y_true = []\n",
        "# for element in test_ds:\n",
        "#     y_true.extend(list(element[1].numpy()))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EU9ErfgyE0Z7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "2ITSwycg8AzG"
      ],
      "name": "Multimodal.ipynb",
      "provenance": [],
      "mount_file_id": "1x6_cP5LupRYKPcrpBbUdgIINKmIOuoZ0",
      "authorship_tag": "ABX9TyN+4/AannM3ZhnOhnUk2Zz9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}